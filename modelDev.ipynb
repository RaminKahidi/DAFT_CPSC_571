{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'c:\\users\\ramin kahidi\\documents\\github\\daft_cpsc_571\\.venv\\lib\\site-packages\\~orch'.\n",
      "  You can safely remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting torch==1.8.1+cu102\n",
      "  Downloading https://download.pytorch.org/whl/cu102/torch-1.8.1%2Bcu102-cp37-cp37m-win_amd64.whl (1387.1 MB)\n",
      "     ---------------------------------------- 1.4/1.4 GB 2.7 MB/s eta 0:00:00\n",
      "Collecting torchvision==0.9.1+cu102\n",
      "  Downloading https://download.pytorch.org/whl/cu102/torchvision-0.9.1%2Bcu102-cp37-cp37m-win_amd64.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 2.7 MB/s eta 0:00:00\n",
      "Collecting torchaudio===0.8.1\n",
      "  Downloading torchaudio-0.8.1-cp37-none-win_amd64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ramin kahidi\\documents\\github\\daft_cpsc_571\\.venv\\lib\\site-packages (from torch==1.8.1+cu102) (4.7.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ramin kahidi\\documents\\github\\daft_cpsc_571\\.venv\\lib\\site-packages (from torch==1.8.1+cu102) (1.21.6)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\ramin kahidi\\documents\\github\\daft_cpsc_571\\.venv\\lib\\site-packages (from torchvision==0.9.1+cu102) (9.5.0)\n",
      "Downloading torchaudio-0.8.1-cp37-none-win_amd64.whl (109 kB)\n",
      "   -------------------------------------- 109.3/109.3 kB 908.9 kB/s eta 0:00:00\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.13.1\n",
      "    Uninstalling torch-1.13.1:\n",
      "      Successfully uninstalled torch-1.13.1\n",
      "Successfully installed torch-1.8.1+cu102 torchaudio-0.8.1 torchvision-0.9.1+cu102\n"
     ]
    }
   ],
   "source": [
    "# !pip install monai\n",
    "# !pip install scikit-learn\n",
    "# !pip install torch==1.8.1+cu102 torchvision==0.9.1+cu102 torchaudio===0.8.1 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# import customDataLoader as CombinedDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor filenames:  ['Breast_MRI_001', 'Breast_MRI_002', 'Breast_MRI_003', 'Breast_MRI_004', 'Breast_MRI_005']\n",
      "row 0: Date of Birth (Days)                               0.705925\n",
      "Image Position of Patient (Y)                      0.180863\n",
      "Image Position of Patient (Z)                      0.746579\n",
      "Image Position of Patient (X)                      0.068046\n",
      "Days to MRI (From the Date of Diagnosis)           0.255952\n",
      "TR (Repetition Time)                               0.150454\n",
      "TE (Echo Time)                                     0.073041\n",
      "Oncotype score                                     0.241581\n",
      "Staging(Nodes)#(Nx replaced by -1)[N]_0.0          0.000000\n",
      "Staging(Metastasis)#(Mx -replaced by -1)[M]_0.0    1.000000\n",
      "Race and Ethnicity_1                               0.000000\n",
      "Tumor Progression_1.0                              0.000000\n",
      "Tumor Progression_2.0                              1.000000\n",
      "Tumor Progression_3.0                              0.000000\n",
      "Tumor Progression_4.0                              0.000000\n",
      "Name: 0, dtype: float64\n",
      "checkpoint 1\n",
      "img shape: (160, 448, 448)\n",
      "padded image shape: torch.Size([210, 512, 512])\n",
      "tensor shape: torch.Size([1, 512, 512, 210])\n",
      "Label is:  tensor([0., 1., 0., 0.])\n",
      "feature count: 11\n",
      "checkpoint 3\n",
      "Batch 1\n",
      "Image shape: torch.Size([1, 1, 512, 512, 210])\n",
      "Label: tensor([[0., 1., 0., 0.]])\n",
      "Tabular data shape: torch.Size([1, 11])\n",
      "-----------------------------\n",
      "checkpoint 1\n",
      "img shape: (160, 448, 448)\n",
      "padded image shape: torch.Size([210, 512, 512])\n",
      "tensor shape: torch.Size([1, 512, 512, 210])\n",
      "Label is:  tensor([0., 1., 0., 0.])\n",
      "feature count: 11\n",
      "checkpoint 3\n",
      "Batch 2\n",
      "Image shape: torch.Size([1, 1, 512, 512, 210])\n",
      "Label: tensor([[0., 1., 0., 0.]])\n",
      "Tabular data shape: torch.Size([1, 11])\n",
      "-----------------------------\n",
      "checkpoint 1\n",
      "img shape: (142, 512, 512)\n",
      "padded image shape: torch.Size([210, 512, 512])\n",
      "tensor shape: torch.Size([1, 512, 512, 210])\n",
      "Label is:  tensor([0., 1., 0., 0.])\n",
      "feature count: 11\n",
      "checkpoint 3\n",
      "Batch 3\n",
      "Image shape: torch.Size([1, 1, 512, 512, 210])\n",
      "Label: tensor([[0., 1., 0., 0.]])\n",
      "Tabular data shape: torch.Size([1, 11])\n",
      "-----------------------------\n",
      "checkpoint 1\n",
      "img shape: (156, 512, 512)\n",
      "padded image shape: torch.Size([210, 512, 512])\n",
      "tensor shape: torch.Size([1, 512, 512, 210])\n",
      "Label is:  tensor([0., 1., 0., 0.])\n",
      "feature count: 11\n",
      "checkpoint 3\n",
      "Batch 4\n",
      "Image shape: torch.Size([1, 1, 512, 512, 210])\n",
      "Label: tensor([[0., 1., 0., 0.]])\n",
      "Tabular data shape: torch.Size([1, 11])\n",
      "-----------------------------\n",
      "checkpoint 1\n",
      "img shape: (164, 512, 512)\n",
      "padded image shape: torch.Size([210, 512, 512])\n",
      "tensor shape: torch.Size([1, 512, 512, 210])\n",
      "Label is:  tensor([1., 0., 0., 0.])\n",
      "feature count: 11\n",
      "checkpoint 3\n",
      "Batch 5\n",
      "Image shape: torch.Size([1, 1, 512, 512, 210])\n",
      "Label: tensor([[1., 0., 0., 0.]])\n",
      "Tabular data shape: torch.Size([1, 11])\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "from customDataLoader import CombinedDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "MRI_dir = \"./RawDataset/MRIs/\"\n",
    "# tabular_dir = \"./RawDataset/Clinical_and_Other_Features.xlsx\"\n",
    "tabular_dir = \"./RawDataset/cleaned.csv\"\n",
    "\n",
    "# Instantiate your dataset\n",
    "dataset = CombinedDataset(data_dir=MRI_dir, tabular_dir=tabular_dir)\n",
    "\n",
    "# Instantiate the DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Iterate over the DataLoader and print the shape of the outputs\n",
    "for i, (img, label, tab_data) in enumerate(dataloader):\n",
    "    print(f\"Batch {i+1}\")\n",
    "    print(f\"Image shape: {img.shape}\")\n",
    "    print(f\"Label: {label}\")\n",
    "    print(f\"Tabular data shape: {tab_data.shape}\")\n",
    "    print(\"-----------------------------\")\n",
    "\n",
    "    # For testing, you might want to break the loop after a few batches\n",
    "    if i == 10:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Training completed.\n",
      "MONAI version: 1.1.0\n",
      "Numpy version: 1.21.6\n",
      "Pytorch version: 1.8.1+cu102\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: a2ec3752f54bfc3b40e7952234fbeb5452ed63e3\n",
      "MONAI __file__: c:\\Users\\Ramin Kahidi\\Documents\\GitHub\\DAFT_CPSC_571\\.venv\\lib\\site-packages\\monai\\__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "scikit-image version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Pillow version: 9.5.0\n",
      "Tensorboard version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: 0.9.1+cu102\n",
      "tqdm version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.8\n",
      "pandas version: 1.3.5\n",
      "einops version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n",
      "DAFT\n",
      "Tensor filenames:  ['Breast_MRI_001', 'Breast_MRI_002', 'Breast_MRI_003', 'Breast_MRI_004', 'Breast_MRI_005']\n",
      "row 0: Date of Birth (Days)                               0.705925\n",
      "Image Position of Patient (Y)                      0.180863\n",
      "Image Position of Patient (Z)                      0.746579\n",
      "Image Position of Patient (X)                      0.068046\n",
      "Days to MRI (From the Date of Diagnosis)           0.255952\n",
      "TR (Repetition Time)                               0.150454\n",
      "TE (Echo Time)                                     0.073041\n",
      "Oncotype score                                     0.241581\n",
      "Staging(Nodes)#(Nx replaced by -1)[N]_0.0          0.000000\n",
      "Staging(Metastasis)#(Mx -replaced by -1)[M]_0.0    1.000000\n",
      "Race and Ethnicity_1                               0.000000\n",
      "Tumor Progression_1.0                              0.000000\n",
      "Tumor Progression_2.0                              1.000000\n",
      "Tumor Progression_3.0                              0.000000\n",
      "Tumor Progression_4.0                              0.000000\n",
      "Name: 0, dtype: float64\n",
      "Epoch 1/100\n",
      "Training labels: tensor([[0., 1., 0., 0.]], device='cuda:0')\n",
      "Logits shape before squeeze: torch.Size([1, 4])\n",
      "[0.1929931640625, -0.210693359375, 0.036865234375, 0.09222412109375]\n",
      "Logits shape: torch.Size([1, 4])\n",
      "Labels shape: torch.Size([1, 4])\n",
      "[0.1929931640625, -0.210693359375, 0.036865234375, 0.09222412109375]\n",
      "This is the real loss :  tensor(0.3782, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "train_records:   Epoch  Batch                           Prediction      Loss  \\\n",
      "0     0    NaN  [[0.193, -0.2107, 0.03687, 0.0922]]  0.378222   \n",
      "\n",
      "               True Value  \n",
      "0  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "Training labels: tensor([[0., 1., 0., 0.]], device='cuda:0')\n",
      "Logits shape before squeeze: torch.Size([1, 4])\n",
      "[0.12890625, -0.07568359375, 0.05682373046875, 0.072265625]\n",
      "Logits shape: torch.Size([1, 4])\n",
      "Labels shape: torch.Size([1, 4])\n",
      "[0.12890625, -0.07568359375, 0.05682373046875, 0.072265625]\n",
      "This is the real loss :  tensor(0.2955, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "train_records:   Epoch  Batch                             Prediction      Loss  \\\n",
      "0     0    NaN    [[0.193, -0.2107, 0.03687, 0.0922]]  0.378222   \n",
      "1     0    NaN  [[0.1289, -0.0757, 0.05682, 0.07227]]  0.295541   \n",
      "\n",
      "               True Value  \n",
      "0  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "1  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "Training labels: tensor([[0., 1., 0., 0.]], device='cuda:0')\n",
      "Logits shape before squeeze: torch.Size([1, 4])\n",
      "[0.0875244140625, -0.03997802734375, -0.00833892822265625, 0.079833984375]\n",
      "Logits shape: torch.Size([1, 4])\n",
      "Labels shape: torch.Size([1, 4])\n",
      "[0.0875244140625, -0.03997802734375, -0.00833892822265625, 0.079833984375]\n",
      "This is the real loss :  tensor(0.2739, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "train_records:   Epoch  Batch                               Prediction      Loss  \\\n",
      "0     0    NaN      [[0.193, -0.2107, 0.03687, 0.0922]]  0.378222   \n",
      "1     0    NaN    [[0.1289, -0.0757, 0.05682, 0.07227]]  0.295541   \n",
      "2     0    NaN  [[0.0875, -0.03998, -0.00834, 0.07983]]  0.273914   \n",
      "\n",
      "               True Value  \n",
      "0  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "1  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "2  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "Training labels: tensor([[1., 0., 0., 0.]], device='cuda:0')\n",
      "Logits shape before squeeze: torch.Size([1, 4])\n",
      "[0.059600830078125, 0.0234222412109375, 0.0097503662109375, 0.0762939453125]\n",
      "Logits shape: torch.Size([1, 4])\n",
      "Labels shape: torch.Size([1, 4])\n",
      "[0.059600830078125, 0.0234222412109375, 0.0097503662109375, 0.0762939453125]\n",
      "This is the real loss :  tensor(0.2227, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "train_records:   Epoch  Batch                               Prediction      Loss  \\\n",
      "0     0    NaN      [[0.193, -0.2107, 0.03687, 0.0922]]  0.378222   \n",
      "1     0    NaN    [[0.1289, -0.0757, 0.05682, 0.07227]]  0.295541   \n",
      "2     0    NaN  [[0.0875, -0.03998, -0.00834, 0.07983]]  0.273914   \n",
      "3     0    NaN     [[0.0596, 0.02342, 0.00975, 0.0763]]  0.222704   \n",
      "\n",
      "               True Value  \n",
      "0  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "1  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "2  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "3  [[1.0, 0.0, 0.0, 0.0]]  \n",
      "Training labels: tensor([[0., 1., 0., 0.]], device='cuda:0')\n",
      "Logits shape before squeeze: torch.Size([1, 4])\n",
      "[0.11474609375, 0.029327392578125, -0.02362060546875, 0.06591796875]\n",
      "Logits shape: torch.Size([1, 4])\n",
      "Labels shape: torch.Size([1, 4])\n",
      "[0.11474609375, 0.029327392578125, -0.02362060546875, 0.06591796875]\n",
      "This is the real loss :  tensor(0.2401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "train_records:   Epoch  Batch                               Prediction      Loss  \\\n",
      "0     0    NaN      [[0.193, -0.2107, 0.03687, 0.0922]]  0.378222   \n",
      "1     0    NaN    [[0.1289, -0.0757, 0.05682, 0.07227]]  0.295541   \n",
      "2     0    NaN  [[0.0875, -0.03998, -0.00834, 0.07983]]  0.273914   \n",
      "3     0    NaN     [[0.0596, 0.02342, 0.00975, 0.0763]]  0.222704   \n",
      "4     0    NaN   [[0.11475, 0.02933, -0.02362, 0.0659]]  0.240069   \n",
      "\n",
      "               True Value  \n",
      "0  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "1  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "2  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "3  [[1.0, 0.0, 0.0, 0.0]]  \n",
      "4  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "Epoch 2/100\n",
      "Logits shape before squeeze: torch.Size([1, 4])\n",
      "[0.1124267578125, 0.06494140625, -0.046722412109375, 0.051116943359375]\n",
      "Logits shape: torch.Size([1, 4])\n",
      "Labels shape: torch.Size([1, 4])\n",
      "[0.1124267578125, 0.06494140625, -0.046722412109375, 0.051116943359375]\n",
      "This is the real loss :  tensor(0.2229, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "train_records:   Epoch  Batch                               Prediction      Loss  \\\n",
      "0     0    NaN      [[0.193, -0.2107, 0.03687, 0.0922]]  0.378222   \n",
      "1     0    NaN    [[0.1289, -0.0757, 0.05682, 0.07227]]  0.295541   \n",
      "2     0    NaN  [[0.0875, -0.03998, -0.00834, 0.07983]]  0.273914   \n",
      "3     0    NaN     [[0.0596, 0.02342, 0.00975, 0.0763]]  0.222704   \n",
      "4     0    NaN   [[0.11475, 0.02933, -0.02362, 0.0659]]  0.240069   \n",
      "5     1    NaN   [[0.1124, 0.06494, -0.04672, 0.05112]]  0.222943   \n",
      "\n",
      "               True Value  \n",
      "0  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "1  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "2  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "3  [[1.0, 0.0, 0.0, 0.0]]  \n",
      "4  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "5  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "Logits shape before squeeze: torch.Size([1, 4])\n",
      "[0.066650390625, 0.1318359375, -0.07745361328125, 0.0266265869140625]\n",
      "Logits shape: torch.Size([1, 4])\n",
      "Labels shape: torch.Size([1, 4])\n",
      "[0.066650390625, 0.1318359375, -0.07745361328125, 0.0266265869140625]\n",
      "This is the real loss :  tensor(0.1912, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "train_records:   Epoch  Batch                               Prediction      Loss  \\\n",
      "0     0    NaN      [[0.193, -0.2107, 0.03687, 0.0922]]  0.378222   \n",
      "1     0    NaN    [[0.1289, -0.0757, 0.05682, 0.07227]]  0.295541   \n",
      "2     0    NaN  [[0.0875, -0.03998, -0.00834, 0.07983]]  0.273914   \n",
      "3     0    NaN     [[0.0596, 0.02342, 0.00975, 0.0763]]  0.222704   \n",
      "4     0    NaN   [[0.11475, 0.02933, -0.02362, 0.0659]]  0.240069   \n",
      "5     1    NaN   [[0.1124, 0.06494, -0.04672, 0.05112]]  0.222943   \n",
      "6     1    NaN   [[0.06665, 0.1318, -0.07745, 0.02663]]  0.191215   \n",
      "\n",
      "               True Value  \n",
      "0  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "1  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "2  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "3  [[1.0, 0.0, 0.0, 0.0]]  \n",
      "4  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "5  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "6  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "Logits shape before squeeze: torch.Size([1, 4])\n",
      "[0.06591796875, 0.1209716796875, -0.08538818359375, 0.05255126953125]\n",
      "Logits shape: torch.Size([1, 4])\n",
      "Labels shape: torch.Size([1, 4])\n",
      "[0.06591796875, 0.1209716796875, -0.08538818359375, 0.05255126953125]\n",
      "This is the real loss :  tensor(0.1968, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "train_records:   Epoch  Batch                               Prediction      Loss  \\\n",
      "0     0    NaN      [[0.193, -0.2107, 0.03687, 0.0922]]  0.378222   \n",
      "1     0    NaN    [[0.1289, -0.0757, 0.05682, 0.07227]]  0.295541   \n",
      "2     0    NaN  [[0.0875, -0.03998, -0.00834, 0.07983]]  0.273914   \n",
      "3     0    NaN     [[0.0596, 0.02342, 0.00975, 0.0763]]  0.222704   \n",
      "4     0    NaN   [[0.11475, 0.02933, -0.02362, 0.0659]]  0.240069   \n",
      "5     1    NaN   [[0.1124, 0.06494, -0.04672, 0.05112]]  0.222943   \n",
      "6     1    NaN   [[0.06665, 0.1318, -0.07745, 0.02663]]  0.191215   \n",
      "7     1    NaN      [[0.0659, 0.121, -0.0854, 0.05255]]  0.196772   \n",
      "\n",
      "               True Value  \n",
      "0  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "1  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "2  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "3  [[1.0, 0.0, 0.0, 0.0]]  \n",
      "4  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "5  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "6  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "7  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "Logits shape before squeeze: torch.Size([1, 4])\n",
      "[0.062744140625, 0.2000732421875, -0.0682373046875, 0.0184326171875]\n",
      "Logits shape: torch.Size([1, 4])\n",
      "Labels shape: torch.Size([1, 4])\n",
      "[0.062744140625, 0.2000732421875, -0.0682373046875, 0.0184326171875]\n",
      "This is the real loss :  tensor(0.2309, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "train_records:   Epoch  Batch                               Prediction      Loss  \\\n",
      "0     0    NaN      [[0.193, -0.2107, 0.03687, 0.0922]]  0.378222   \n",
      "1     0    NaN    [[0.1289, -0.0757, 0.05682, 0.07227]]  0.295541   \n",
      "2     0    NaN  [[0.0875, -0.03998, -0.00834, 0.07983]]  0.273914   \n",
      "3     0    NaN     [[0.0596, 0.02342, 0.00975, 0.0763]]  0.222704   \n",
      "4     0    NaN   [[0.11475, 0.02933, -0.02362, 0.0659]]  0.240069   \n",
      "5     1    NaN   [[0.1124, 0.06494, -0.04672, 0.05112]]  0.222943   \n",
      "6     1    NaN   [[0.06665, 0.1318, -0.07745, 0.02663]]  0.191215   \n",
      "7     1    NaN      [[0.0659, 0.121, -0.0854, 0.05255]]  0.196772   \n",
      "8     1    NaN   [[0.06274, 0.2001, -0.06824, 0.01843]]  0.230868   \n",
      "\n",
      "               True Value  \n",
      "0  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "1  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "2  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "3  [[1.0, 0.0, 0.0, 0.0]]  \n",
      "4  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "5  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "6  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "7  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "8  [[1.0, 0.0, 0.0, 0.0]]  \n",
      "Logits shape before squeeze: torch.Size([1, 4])\n",
      "[0.08819580078125, 0.244873046875, -0.06854248046875, 0.05364990234375]\n",
      "Logits shape: torch.Size([1, 4])\n",
      "Labels shape: torch.Size([1, 4])\n",
      "[0.08819580078125, 0.244873046875, -0.06854248046875, 0.05364990234375]\n",
      "This is the real loss :  tensor(0.1464, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "train_records:   Epoch  Batch                               Prediction      Loss  \\\n",
      "0     0    NaN      [[0.193, -0.2107, 0.03687, 0.0922]]  0.378222   \n",
      "1     0    NaN    [[0.1289, -0.0757, 0.05682, 0.07227]]  0.295541   \n",
      "2     0    NaN  [[0.0875, -0.03998, -0.00834, 0.07983]]  0.273914   \n",
      "3     0    NaN     [[0.0596, 0.02342, 0.00975, 0.0763]]  0.222704   \n",
      "4     0    NaN   [[0.11475, 0.02933, -0.02362, 0.0659]]  0.240069   \n",
      "5     1    NaN   [[0.1124, 0.06494, -0.04672, 0.05112]]  0.222943   \n",
      "6     1    NaN   [[0.06665, 0.1318, -0.07745, 0.02663]]  0.191215   \n",
      "7     1    NaN      [[0.0659, 0.121, -0.0854, 0.05255]]  0.196772   \n",
      "8     1    NaN   [[0.06274, 0.2001, -0.06824, 0.01843]]  0.230868   \n",
      "9     1    NaN    [[0.0882, 0.2449, -0.06854, 0.05365]]  0.146393   \n",
      "\n",
      "               True Value  \n",
      "0  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "1  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "2  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "3  [[1.0, 0.0, 0.0, 0.0]]  \n",
      "4  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "5  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "6  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "7  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "8  [[1.0, 0.0, 0.0, 0.0]]  \n",
      "9  [[0.0, 1.0, 0.0, 0.0]]  \n",
      "Logits shape: torch.Size([1, 4])\n",
      "Labels shape: torch.Size([1, 4])\n",
      "[0.16263580322265625, 0.23074008524417877, 0.07316922396421432, 0.05074474215507507]\n",
      "This is the real loss :  0.15653499960899353\n",
      "val_targets: [array([0., 1., 0., 0.], dtype=float32)]\n",
      "val_preds: [0.1626358, 0.23074009, 0.073169224, 0.050744742]\n",
      "Logits shape: torch.Size([1, 4])\n",
      "Labels shape: torch.Size([1, 4])\n",
      "[0.9134410619735718, 0.7554172277450562, 1.4730546474456787, -0.3938632607460022]\n",
      "This is the real loss :  0.9613383710384369\n",
      "val_targets: [array([0., 1., 0., 0.], dtype=float32), array([0., 1., 0., 0.], dtype=float32)]\n",
      "val_preds: [0.1626358, 0.23074009, 0.073169224, 0.050744742, 0.91344106, 0.7554172, 1.4730546, -0.39386326]\n",
      "Logits shape: torch.Size([1, 4])\n",
      "Labels shape: torch.Size([1, 4])\n",
      "[0.1110445037484169, 0.19125433266162872, -0.019802801311016083, 0.5088337063789368]\n",
      "This is the real loss :  1.1927644610404968\n",
      "val_targets: [array([0., 1., 0., 0.], dtype=float32), array([0., 1., 0., 0.], dtype=float32), array([0., 1., 0., 0.], dtype=float32)]\n",
      "val_preds: [0.1626358, 0.23074009, 0.073169224, 0.050744742, 0.91344106, 0.7554172, 1.4730546, -0.39386326, 0.111044504, 0.19125433, -0.019802801, 0.5088337]\n",
      "Logits shape: torch.Size([1, 4])\n",
      "Labels shape: torch.Size([1, 4])\n",
      "[0.11016387492418289, 0.19682839512825012, -0.02672189474105835, 0.4898054003715515]\n",
      "This is the real loss :  1.460557758808136\n",
      "val_targets: [array([0., 1., 0., 0.], dtype=float32), array([0., 1., 0., 0.], dtype=float32), array([0., 1., 0., 0.], dtype=float32), array([1., 0., 0., 0.], dtype=float32)]\n",
      "val_preds: [0.1626358, 0.23074009, 0.073169224, 0.050744742, 0.91344106, 0.7554172, 1.4730546, -0.39386326, 0.111044504, 0.19125433, -0.019802801, 0.5088337, 0.110163875, 0.1968284, -0.026721895, 0.4898054]\n",
      "Logits shape: torch.Size([1, 4])\n",
      "Labels shape: torch.Size([1, 4])\n",
      "[0.04899831861257553, 0.4171817898750305, 0.3853036165237427, 0.29933488368988037]\n",
      "This is the real loss :  1.6055923104286194\n",
      "val_targets: [array([0., 1., 0., 0.], dtype=float32), array([0., 1., 0., 0.], dtype=float32), array([0., 1., 0., 0.], dtype=float32), array([1., 0., 0., 0.], dtype=float32), array([0., 1., 0., 0.], dtype=float32)]\n",
      "val_preds: [0.1626358, 0.23074009, 0.073169224, 0.050744742, 0.91344106, 0.7554172, 1.4730546, -0.39386326, 0.111044504, 0.19125433, -0.019802801, 0.5088337, 0.110163875, 0.1968284, -0.026721895, 0.4898054, 0.04899832, 0.4171818, 0.38530362, 0.29933488]\n",
      "Batch size (logits): 1, Batch size (labels): 1\n",
      "Total Predictions: 20, Total Targets: 5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [5, 20]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24660\\2700982262.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[1;31m# tabular_dir = \"./RawDataset/Clinical_and_Other_Features.xlsx\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[0mtabular_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"./RawDataset/cleaned.csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMRI_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMRI_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtabular_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtabular_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24660\\2700982262.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(MRI_dir, tabular_dir)\u001b[0m\n\u001b[0;32m    164\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Batch size (logits): {logits.shape[0]}, Batch size (labels): {val_labels.shape[0]}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Total Predictions: {len(val_preds)}, Total Targets: {len(val_targets)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m             \u001b[0mval_mae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m             \u001b[0mval_r2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ramin Kahidi\\Documents\\GitHub\\DAFT_CPSC_571\\.venv\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36mmean_absolute_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    190\u001b[0m     \"\"\"\n\u001b[0;32m    191\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[1;32m--> 192\u001b[1;33m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m     )\n\u001b[0;32m    194\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ramin Kahidi\\Documents\\GitHub\\DAFT_CPSC_571\\.venv\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0margument\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \"\"\"\n\u001b[1;32m---> 94\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ramin Kahidi\\Documents\\GitHub\\DAFT_CPSC_571\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    332\u001b[0m         raise ValueError(\n\u001b[0;32m    333\u001b[0m             \u001b[1;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m             \u001b[1;33m%\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m         )\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [5, 20]"
     ]
    }
   ],
   "source": [
    "\n",
    "from DAFT.daft.models.base import BaseModel\n",
    "from DAFT.daft.networks.vol_blocks import ConvBnReLU, DAFTBlock, FilmBlock, ResBlock\n",
    "from DAFT.daft.networks.vol_networks import DAFT\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import monai\n",
    "from monai.transforms import EnsureChannelFirst, Compose, ScaleIntensity\n",
    "import logging\n",
    "import sys\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "from customDataLoader import CombinedDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "\n",
    "def main(MRI_dir, tabular_dir):\n",
    "    \"\"\"\n",
    "    Main function to configure and execute the model training.\n",
    "\n",
    "    Parameters:\n",
    "    - data_dir (str): Directory containing the data files.\n",
    "    - bone_type (str): Type of bone to focus on during training.\n",
    "    \"\"\"\n",
    "    monai.config.print_config()\n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print('DAFT')\n",
    "\n",
    "    model = DAFT(\n",
    "        in_channels=1,  \n",
    "        n_outputs=4, \n",
    "        bn_momentum=0.7,\n",
    "        n_basefilters=4\n",
    "    )\n",
    "    model.to(device)\n",
    "    loss_function = torch.nn.MSELoss()\n",
    "    lr = 1e-3\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "\n",
    "    scaler = GradScaler()\n",
    "    # writer = SummaryWriter()\n",
    "    early_stop_patience = 20\n",
    "    epochs_without_improvement = 0 \n",
    "    # batch_size = 4\n",
    "    batch_size = 1\n",
    "    val_interval = 2\n",
    "    k_folds = 5\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "    # dataset_transforms = Compose([ScaleIntensity(), EnsureChannelFirst(channel_dim=0)])\n",
    "    # dataset = CombinedDataset(data_dir, bone_type, transform=dataset_transforms)\n",
    "\n",
    "    # Instantiate your dataset\n",
    "    dataset = CombinedDataset(data_dir=MRI_dir, tabular_dir=tabular_dir)\n",
    "\n",
    "\n",
    "    fold_results = pd.DataFrame(columns=['Fold', 'Best Val Loss', 'Best Val MAE', 'Best Val R2'])\n",
    "\n",
    "    workers = 1\n",
    "\n",
    "    fold = 0\n",
    "    # for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "        # print(f\"FOLD {fold}\")\n",
    "        # print(\"--------------------------------\")\n",
    "        # print(f\"Train IDs: {train_ids}\")\n",
    "        # print(f\"Test IDs: {test_ids}\")\n",
    "    epochs_without_improvement = 0\n",
    "    # train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    # test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    # train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_subsampler, num_workers=workers, pin_memory=torch.cuda.is_available(), drop_last=True)\n",
    "    # val_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_subsampler, num_workers=workers, pin_memory=torch.cuda.is_available(), drop_last=True)\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, num_workers=workers, pin_memory=torch.cuda.is_available(), drop_last=True)\n",
    "    val_loader = DataLoader(dataset, batch_size=batch_size, num_workers=workers, pin_memory=torch.cuda.is_available(), drop_last=True)\n",
    "\n",
    "    best_val_loss = np.inf\n",
    "    best_val_mae = np.inf\n",
    "    best_val_r2 = -np.inf\n",
    "\n",
    "    train_records = pd.DataFrame(columns=['Epoch', 'Batch', 'Prediction', 'Loss', 'True Value'])\n",
    "    val_records = pd.DataFrame(columns=['Epoch', 'Batch', 'Prediction', 'Loss', 'True Value'])\n",
    "\n",
    "    for epoch in range(10):\n",
    "        print(f\"Epoch {epoch + 1}/100\")\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch_data in train_loader:\n",
    "            inputs, labels, tabular_data = batch_data[0].to(device), batch_data[1].to(device), batch_data[2].to(device)\n",
    "            # inputs = inputs.half()\n",
    "            if epoch == 0:\n",
    "                print(f\"Training labels: {labels}\")\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                output_dict = model(inputs, tabular_data)\n",
    "                logits = output_dict[\"logits\"]\n",
    "                print(f\"Logits shape before squeeze: {logits.shape}\")\n",
    "                for i in range(logits.size(0)):  \n",
    "                    print(logits[i].tolist())\n",
    "                logits = logits.squeeze(1)\n",
    "                print(f\"Logits shape: {logits.shape}\")\n",
    "                print(f\"Labels shape: {labels.shape}\")\n",
    "                for i in range(logits.size(0)):  \n",
    "                    print(logits[i].tolist())  \n",
    "                loss = loss_function(logits.float(), labels.float())\n",
    "                print(\"This is the real loss : \", loss)\n",
    "                \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            epoch_loss += loss.item()\n",
    "            train_records = train_records.append({\n",
    "                'Epoch': epoch,\n",
    "                'Prediction': logits.detach().cpu().numpy(),\n",
    "                'Loss': loss.item(),\n",
    "                'True Value': labels.cpu().numpy()\n",
    "            }, ignore_index=True)\n",
    "            print(f\"train_records: {train_records}\")\n",
    "\n",
    "        epoch_loss /= len(train_loader)\n",
    "\n",
    "        if (epoch + 1) % val_interval == 0:\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            val_preds = []\n",
    "            val_targets = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for val_data in val_loader:\n",
    "                    val_images, val_labels, val_tabular_data = val_data[0].to(device), val_data[1].to(device), val_data[2].to(device)\n",
    "                    if epoch == 0:\n",
    "                        print(f\"Validation labels: {val_labels}\")\n",
    "                        print(f\"Val_tabualr data labels: {val_tabular_data}\")\n",
    "                        print(f\"Validation Images: {val_images.shape}\")\n",
    "                    output_dict = model(val_images, val_tabular_data)\n",
    "                    logits = output_dict[\"logits\"]\n",
    "                    logits = logits.squeeze(1)\n",
    "                    print(f\"Logits shape: {logits.shape}\")\n",
    "                    print(f\"Labels shape: {val_labels.shape}\")\n",
    "                    for i in range(logits.size(0)):\n",
    "                        print(logits[i].tolist())\n",
    "\n",
    "                        \n",
    "                    val_loss += loss_function(logits.float(), val_labels.float()).item()\n",
    "                    print(\"This is the real loss : \", val_loss)\n",
    "                    # val_preds.extend(logits.view(-1).cpu().numpy())\n",
    "                    val_preds.extend(logits.view(-1).cpu().numpy().reshape(-1, 4).tolist())\n",
    "                    val_targets.extend(val_labels.cpu().numpy())\n",
    "                    print(f\"val_targets: {val_targets}\")\n",
    "                    print(f\"val_preds: {val_preds}\")\n",
    "                    val_records = val_records.append({\n",
    "                    'Epoch': epoch,\n",
    "                    'Prediction': logits.detach().cpu().numpy(),\n",
    "                    'Loss': loss.item(),\n",
    "                    'True Value': val_labels.cpu().numpy()\n",
    "                }, ignore_index=True)\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "            print(f\"Batch size (logits): {logits.shape[0]}, Batch size (labels): {val_labels.shape[0]}\")\n",
    "            print(f\"Total Predictions: {len(val_preds)}, Total Targets: {len(val_targets)}\")\n",
    "            # val_mae = mean_absolute_error(val_targets, val_preds)\n",
    "            val_mae = mean_absolute_error(np.array(val_targets).flatten(), np.array(val_preds).flatten())\n",
    "            val_r2 = r2_score(val_targets, val_preds)\n",
    "\n",
    "            print(f\"Validation Loss - Fold {fold}, Epoch {epoch + 1}: {val_loss:.4f}, MAE: {val_mae:.4f}, R2: {val_r2:.4f}\")\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_val_mae = val_mae\n",
    "                best_val_r2 = val_r2\n",
    "                epochs_without_improvement = 0\n",
    "                # Save the model checkpoint if it's the best so far\n",
    "                torch.save(model.state_dict(), f\"Best_Model_Fold_{fold}_Epoch_{epoch}.pth\")\n",
    "            else:\n",
    "                epochs_without_improvement = epochs_without_improvement + 1\n",
    "\n",
    "        if epochs_without_improvement >= early_stop_patience:\n",
    "            print(\"Early stopping triggered for fold:\", fold)\n",
    "            break\n",
    "\n",
    "    fold_results = fold_results.append({\n",
    "        'Fold': fold,\n",
    "        'Best Val Loss': best_val_loss,\n",
    "        'Best Val MAE': best_val_mae,\n",
    "        'Best Val R2': best_val_r2\n",
    "    }, ignore_index=True)\n",
    "    train_records.to_csv(f'train_records_fold_{fold}_epoch_{epoch}.csv', index=False)\n",
    "    val_records.to_csv(f'val_records_fold_{fold}_epoch_{epoch}.csv', index=False)\n",
    "\n",
    "    # print(f\"Completed Fold {fold}\")\n",
    "\n",
    "# writer.close()\n",
    "print(\"Training completed.\")\n",
    "# print(\"Fold Results:\\n\", fold_results)\n",
    "\n",
    "MRI_dir = \"./RawDataset/MRIs/\"\n",
    "# tabular_dir = \"./RawDataset/Clinical_and_Other_Features.xlsx\"\n",
    "tabular_dir = \"./RawDataset/cleaned.csv\"\n",
    "main(MRI_dir=MRI_dir, tabular_dir=tabular_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(test_data_dir, bone_type, model_path):\n",
    "    \"\"\"\n",
    "    Main method to train the ResNet on a training dataset\n",
    "\n",
    "    Parameters:\n",
    "    - test_data_dir (Str): Directory containing the test dataset of HR-pQCT images\n",
    "    - bone_type (char): Which bone is being evaluated (Radius or Tibia)\n",
    "    - model_path: Path to where the previously trained model is saved\n",
    "\n",
    "    Returns:\n",
    "    - Nothing\n",
    "    - Saves the performance metrics to a .csv file\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = load_model(model_path).to(device)\n",
    "    \n",
    "    test_dataset_transforms = Compose([ScaleIntensity(), EnsureChannelFirst(channel_dim=0)])\n",
    "    test_dataset = TensorDataset(test_data_dir, bone_type, transform=test_dataset_transforms)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, num_workers=0, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "    predictions, targets, mae, r2, mse = evaluate_model(model, test_loader, device)\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Predictions': predictions,\n",
    "        'Targets': targets,\n",
    "        'MAE': [mae] * len(predictions),\n",
    "        'R2': [r2] * len(predictions),\n",
    "        'MSE':  [mse] * len(predictions)\n",
    "    })\n",
    "\n",
    "    results_df.to_csv('/home/sergiu.cociuba/BoneLab/DAFT/daft/test_results_daft.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
