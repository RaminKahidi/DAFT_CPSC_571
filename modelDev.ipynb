{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'c:\\users\\ramin kahidi\\documents\\github\\daft_cpsc_571\\.venv\\lib\\site-packages\\~orch'.\n",
      "  You can safely remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting torch==1.8.1+cu102\n",
      "  Downloading https://download.pytorch.org/whl/cu102/torch-1.8.1%2Bcu102-cp37-cp37m-win_amd64.whl (1387.1 MB)\n",
      "     ---------------------------------------- 1.4/1.4 GB 2.7 MB/s eta 0:00:00\n",
      "Collecting torchvision==0.9.1+cu102\n",
      "  Downloading https://download.pytorch.org/whl/cu102/torchvision-0.9.1%2Bcu102-cp37-cp37m-win_amd64.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 2.7 MB/s eta 0:00:00\n",
      "Collecting torchaudio===0.8.1\n",
      "  Downloading torchaudio-0.8.1-cp37-none-win_amd64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ramin kahidi\\documents\\github\\daft_cpsc_571\\.venv\\lib\\site-packages (from torch==1.8.1+cu102) (4.7.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ramin kahidi\\documents\\github\\daft_cpsc_571\\.venv\\lib\\site-packages (from torch==1.8.1+cu102) (1.21.6)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\ramin kahidi\\documents\\github\\daft_cpsc_571\\.venv\\lib\\site-packages (from torchvision==0.9.1+cu102) (9.5.0)\n",
      "Downloading torchaudio-0.8.1-cp37-none-win_amd64.whl (109 kB)\n",
      "   -------------------------------------- 109.3/109.3 kB 908.9 kB/s eta 0:00:00\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.13.1\n",
      "    Uninstalling torch-1.13.1:\n",
      "      Successfully uninstalled torch-1.13.1\n",
      "Successfully installed torch-1.8.1+cu102 torchaudio-0.8.1 torchvision-0.9.1+cu102\n"
     ]
    }
   ],
   "source": [
    "# !pip install monai\n",
    "# !pip install scikit-learn\n",
    "# !pip install torch==1.8.1+cu102 torchvision==0.9.1+cu102 torchaudio===0.8.1 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# import customDataLoader as CombinedDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor filenames:  ['Breast_MRI_001', 'Breast_MRI_002', 'Breast_MRI_003', 'Breast_MRI_004', 'Breast_MRI_005']\n",
      "row 0: Patient ID                                  Breast_MRI_001\n",
      "Date of Birth (Days)                              0.705925\n",
      "Image Position of Patient (Y)                     0.180863\n",
      "Image Position of Patient (Z)                     0.746579\n",
      "Image Position of Patient (X)                     0.068046\n",
      "Days to MRI (From the Date of Diagnosis)          0.255952\n",
      "TR (Repetition Time)                              0.150454\n",
      "TE (Echo Time)                                    0.073041\n",
      "Oncotype score                                    0.241581\n",
      "Race and Ethnicity_1                                     0\n",
      "Slice Thickness _18                                      0\n",
      "Tumor Grade(M)\\n(Mitotic)_1.0                            1\n",
      "Tumor Grade(M)\\n(Mitotic)_3.0                            0\n",
      "Bilateral Information_0                                  1\n",
      "Tumor Grade(T)\\n(Tubule)_3.0                             1\n",
      "FOV Computed (Field of View) in cm _11                   0\n",
      "Tumor Progression_1.0                                    0\n",
      "Tumor Progression_2.0                                    1\n",
      "Tumor Progression_3.0                                    0\n",
      "Tumor Progression_4.0                                    0\n",
      "Name: 0, dtype: object\n",
      "checkpoint 1\n",
      "img shape: (156, 512, 512)\n",
      "padded image shape: torch.Size([210, 512, 512])\n",
      "tensor shape: torch.Size([1, 512, 512, 210])\n",
      "Label is:  tensor([0., 1., 0., 0.])\n",
      "feature count: 16\n",
      "checkpoint 3\n",
      "Batch 1\n",
      "Image shape: torch.Size([1, 1, 512, 512, 210])\n",
      "Label: tensor([[0., 1., 0., 0.]])\n",
      "Tabular data shape: torch.Size([1, 15])\n",
      "-----------------------------\n",
      "checkpoint 1\n",
      "img shape: (160, 448, 448)\n",
      "padded image shape: torch.Size([210, 512, 512])\n",
      "tensor shape: torch.Size([1, 512, 512, 210])\n",
      "Label is:  tensor([0., 1., 0., 0.])\n",
      "feature count: 16\n",
      "checkpoint 3\n",
      "Batch 2\n",
      "Image shape: torch.Size([1, 1, 512, 512, 210])\n",
      "Label: tensor([[0., 1., 0., 0.]])\n",
      "Tabular data shape: torch.Size([1, 15])\n",
      "-----------------------------\n",
      "checkpoint 1\n",
      "img shape: (160, 448, 448)\n",
      "padded image shape: torch.Size([210, 512, 512])\n",
      "tensor shape: torch.Size([1, 512, 512, 210])\n",
      "Label is:  tensor([0., 1., 0., 0.])\n",
      "feature count: 16\n",
      "checkpoint 3\n",
      "Batch 3\n",
      "Image shape: torch.Size([1, 1, 512, 512, 210])\n",
      "Label: tensor([[0., 1., 0., 0.]])\n",
      "Tabular data shape: torch.Size([1, 15])\n",
      "-----------------------------\n",
      "checkpoint 1\n",
      "img shape: (164, 512, 512)\n",
      "padded image shape: torch.Size([210, 512, 512])\n",
      "tensor shape: torch.Size([1, 512, 512, 210])\n",
      "Label is:  tensor([1., 0., 0., 0.])\n",
      "feature count: 16\n",
      "checkpoint 3\n",
      "Batch 4\n",
      "Image shape: torch.Size([1, 1, 512, 512, 210])\n",
      "Label: tensor([[1., 0., 0., 0.]])\n",
      "Tabular data shape: torch.Size([1, 15])\n",
      "-----------------------------\n",
      "checkpoint 1\n",
      "img shape: (142, 512, 512)\n",
      "padded image shape: torch.Size([210, 512, 512])\n",
      "tensor shape: torch.Size([1, 512, 512, 210])\n",
      "Label is:  tensor([0., 1., 0., 0.])\n",
      "feature count: 16\n",
      "checkpoint 3\n",
      "Batch 5\n",
      "Image shape: torch.Size([1, 1, 512, 512, 210])\n",
      "Label: tensor([[0., 1., 0., 0.]])\n",
      "Tabular data shape: torch.Size([1, 15])\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "from customDataLoader import CombinedDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "MRI_dir = \"./RawDataset/MRIs/\"\n",
    "# tabular_dir = \"./RawDataset/Clinical_and_Other_Features.xlsx\"\n",
    "tabular_dir = \"./RawDataset/cleaned.csv\"\n",
    "\n",
    "# Instantiate your dataset\n",
    "dataset = CombinedDataset(data_dir=MRI_dir, tabular_dir=tabular_dir)\n",
    "\n",
    "# Instantiate the DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Iterate over the DataLoader and print the shape of the outputs\n",
    "for i, (img, label, tab_data) in enumerate(dataloader):\n",
    "    print(f\"Batch {i+1}\")\n",
    "    print(f\"Image shape: {img.shape}\")\n",
    "    print(f\"Label: {label}\")\n",
    "    print(f\"Tabular data shape: {tab_data.shape}\")\n",
    "    print(\"-----------------------------\")\n",
    "\n",
    "    # For testing, you might want to break the loop after a few batches\n",
    "    if i == 10:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Training completed.\n",
      "MONAI version: 1.1.0\n",
      "Numpy version: 1.21.6\n",
      "Pytorch version: 1.8.1+cu102\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: a2ec3752f54bfc3b40e7952234fbeb5452ed63e3\n",
      "MONAI __file__: c:\\Users\\Ramin Kahidi\\Documents\\GitHub\\DAFT_CPSC_571\\.venv\\lib\\site-packages\\monai\\__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "scikit-image version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Pillow version: 9.5.0\n",
      "Tensorboard version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: 0.9.1+cu102\n",
      "tqdm version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.8\n",
      "pandas version: 1.3.5\n",
      "einops version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n",
      "DAFT\n",
      "Tensor filenames:  ['Breast_MRI_001', 'Breast_MRI_002', 'Breast_MRI_003', 'Breast_MRI_004', 'Breast_MRI_005']\n",
      "row 0: Patient ID                                  Breast_MRI_001\n",
      "Date of Birth (Days)                              0.705925\n",
      "Image Position of Patient (Y)                     0.180863\n",
      "Image Position of Patient (Z)                     0.746579\n",
      "Image Position of Patient (X)                     0.068046\n",
      "Days to MRI (From the Date of Diagnosis)          0.255952\n",
      "TR (Repetition Time)                              0.150454\n",
      "TE (Echo Time)                                    0.073041\n",
      "Oncotype score                                    0.241581\n",
      "Race and Ethnicity_1                                     0\n",
      "Slice Thickness _18                                      0\n",
      "Tumor Grade(M)\\n(Mitotic)_1.0                            1\n",
      "Tumor Grade(M)\\n(Mitotic)_3.0                            0\n",
      "Bilateral Information_0                                  1\n",
      "Tumor Grade(T)\\n(Tubule)_3.0                             1\n",
      "FOV Computed (Field of View) in cm _11                   0\n",
      "Tumor Progression_1.0                                    0\n",
      "Tumor Progression_2.0                                    1\n",
      "Tumor Progression_3.0                                    0\n",
      "Tumor Progression_4.0                                    0\n",
      "Name: 0, dtype: object\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from DAFT.daft.models.base import BaseModel\n",
    "from DAFT.daft.networks.vol_blocks import ConvBnReLU, DAFTBlock, FilmBlock, ResBlock\n",
    "from DAFT.daft.networks.vol_networks import DAFT\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import monai\n",
    "from monai.transforms import EnsureChannelFirst, Compose, ScaleIntensity\n",
    "import logging\n",
    "import sys\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "from customDataLoader import CombinedDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "\n",
    "def main(MRI_dir, tabular_dir):\n",
    "    \"\"\"\n",
    "    Main function to configure and execute the model training.\n",
    "\n",
    "    Parameters:\n",
    "    - data_dir (str): Directory containing the data files.\n",
    "    - bone_type (str): Type of bone to focus on during training.\n",
    "    \"\"\"\n",
    "    monai.config.print_config()\n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print('DAFT')\n",
    "\n",
    "    model = DAFT(\n",
    "        in_channels=1,  \n",
    "        n_outputs=4, \n",
    "        bn_momentum=0.7,\n",
    "        n_basefilters=4\n",
    "    )\n",
    "    model.to(device)\n",
    "    loss_function = torch.nn.MSELoss()\n",
    "    lr = 1e-3\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "\n",
    "    scaler = GradScaler()\n",
    "    # writer = SummaryWriter()\n",
    "    early_stop_patience = 20\n",
    "    epochs_without_improvement = 0 \n",
    "    # batch_size = 4\n",
    "    batch_size = 1\n",
    "    val_interval = 2\n",
    "    k_folds = 5\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "    # dataset_transforms = Compose([ScaleIntensity(), EnsureChannelFirst(channel_dim=0)])\n",
    "    # dataset = CombinedDataset(data_dir, bone_type, transform=dataset_transforms)\n",
    "\n",
    "    # Instantiate your dataset\n",
    "    dataset = CombinedDataset(data_dir=MRI_dir, tabular_dir=tabular_dir)\n",
    "\n",
    "\n",
    "    fold_results = pd.DataFrame(columns=['Fold', 'Best Val Loss', 'Best Val MAE', 'Best Val R2'])\n",
    "\n",
    "    workers = 1\n",
    "\n",
    "    fold = 0\n",
    "    # for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "        # print(f\"FOLD {fold}\")\n",
    "        # print(\"--------------------------------\")\n",
    "        # print(f\"Train IDs: {train_ids}\")\n",
    "        # print(f\"Test IDs: {test_ids}\")\n",
    "    epochs_without_improvement = 0\n",
    "    # train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    # test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    # train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_subsampler, num_workers=workers, pin_memory=torch.cuda.is_available(), drop_last=True)\n",
    "    # val_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_subsampler, num_workers=workers, pin_memory=torch.cuda.is_available(), drop_last=True)\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, num_workers=workers, pin_memory=torch.cuda.is_available(), drop_last=True)\n",
    "    val_loader = DataLoader(dataset, batch_size=batch_size, num_workers=workers, pin_memory=torch.cuda.is_available(), drop_last=True)\n",
    "\n",
    "    best_val_loss = np.inf\n",
    "    best_val_mae = np.inf\n",
    "    best_val_r2 = -np.inf\n",
    "\n",
    "    train_records = pd.DataFrame(columns=['Epoch', 'Batch', 'Prediction', 'Loss', 'True Value'])\n",
    "    val_records = pd.DataFrame(columns=['Epoch', 'Batch', 'Prediction', 'Loss', 'True Value'])\n",
    "\n",
    "    for epoch in range(1):\n",
    "        print(f\"Epoch {epoch + 1}/100\")\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch_data in train_loader:\n",
    "            inputs, labels, tabular_data = batch_data[0].to(device), batch_data[1].to(device), batch_data[2].to(device)\n",
    "            # inputs = inputs.half()\n",
    "            if epoch == 0:\n",
    "                print(f\"Training labels: {labels}\")\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                output_dict = model(inputs, tabular_data)\n",
    "                logits = output_dict[\"logits\"]\n",
    "                print(f\"Logits shape before squeeze: {logits.shape}\")\n",
    "                for i in range(logits.size(0)):  \n",
    "                    print(logits[i].tolist())\n",
    "                logits = logits.squeeze(1)\n",
    "                print(f\"Logits shape: {logits.shape}\")\n",
    "                print(f\"Labels shape: {labels.shape}\")\n",
    "                for i in range(logits.size(0)):  \n",
    "                    print(logits[i].tolist())  \n",
    "                loss = loss_function(logits.float(), labels.float())\n",
    "                print(\"This is the real loss : \", loss)\n",
    "                \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            epoch_loss += loss.item()\n",
    "            train_records = train_records.append({\n",
    "                'Epoch': epoch,\n",
    "                'Prediction': logits.detach().cpu().numpy(),\n",
    "                'Loss': loss.item(),\n",
    "                'True Value': labels.cpu().numpy()\n",
    "            }, ignore_index=True)\n",
    "            print(f\"train_records: {train_records}\")\n",
    "\n",
    "        epoch_loss /= len(train_loader)\n",
    "\n",
    "        if (epoch + 1) % val_interval == 0:\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            val_preds = []\n",
    "            val_targets = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for val_data in val_loader:\n",
    "                    val_images, val_labels, val_tabular_data = val_data[0].to(device), val_data[1].to(device), val_data[2].to(device)\n",
    "                    if epoch == 0:\n",
    "                        print(f\"Validation labels: {val_labels}\")\n",
    "                        print(f\"Val_tabualr data labels: {val_tabular_data}\")\n",
    "                        print(f\"Validation Images: {val_images.shape}\")\n",
    "                    output_dict = model(val_images, val_tabular_data)\n",
    "                    logits = output_dict[\"logits\"]\n",
    "                    logits = logits.squeeze(1)\n",
    "                    print(f\"Logits shape: {logits.shape}\")\n",
    "                    print(f\"Labels shape: {val_labels.shape}\")\n",
    "                    for i in range(logits.size(0)):\n",
    "                        print(logits[i].tolist())\n",
    "\n",
    "                        \n",
    "                    val_loss += loss_function(logits.float(), val_labels.float()).item()\n",
    "                    print(\"This is the real loss : \", val_loss)\n",
    "                    # val_preds.extend(logits.view(-1).cpu().numpy())\n",
    "                    val_preds.extend(logits.view(-1).cpu().numpy().reshape(-1, 4).tolist())\n",
    "                    val_targets.extend(val_labels.cpu().numpy())\n",
    "                    print(f\"val_targets: {val_targets}\")\n",
    "                    print(f\"val_preds: {val_preds}\")\n",
    "                    val_records = val_records.append({\n",
    "                    'Epoch': epoch,\n",
    "                    'Prediction': logits.detach().cpu().numpy(),\n",
    "                    'Loss': loss.item(),\n",
    "                    'True Value': val_labels.cpu().numpy()\n",
    "                }, ignore_index=True)\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "            print(f\"Batch size (logits): {logits.shape[0]}, Batch size (labels): {val_labels.shape[0]}\")\n",
    "            print(f\"Total Predictions: {len(val_preds)}, Total Targets: {len(val_targets)}\")\n",
    "            # val_mae = mean_absolute_error(val_targets, val_preds)\n",
    "            val_mae = mean_absolute_error(np.array(val_targets).flatten(), np.array(val_preds).flatten())\n",
    "            val_r2 = r2_score(val_targets, val_preds)\n",
    "\n",
    "            print(f\"Validation Loss - Fold {fold}, Epoch {epoch + 1}: {val_loss:.4f}, MAE: {val_mae:.4f}, R2: {val_r2:.4f}\")\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_val_mae = val_mae\n",
    "                best_val_r2 = val_r2\n",
    "                epochs_without_improvement = 0\n",
    "                # Save the model checkpoint if it's the best so far\n",
    "                torch.save(model.state_dict(), f\"Best_Model_Fold_{fold}_Epoch_{epoch}.pth\")\n",
    "            else:\n",
    "                epochs_without_improvement = epochs_without_improvement + 1\n",
    "\n",
    "        if epochs_without_improvement >= early_stop_patience:\n",
    "            print(\"Early stopping triggered for fold:\", fold)\n",
    "            break\n",
    "\n",
    "        # save a temporary output file every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            train_records.to_csv(f'./tempOutputs/train_records_fold_{fold}_epoch_{epoch}.csv', index=False)\n",
    "            val_records.to_csv(f'./tempOutputs/val_records_fold_{fold}_epoch_{epoch}.csv', index=False)\n",
    "        \n",
    "\n",
    "    fold_results = fold_results.append({\n",
    "        'Fold': fold,\n",
    "        'Best Val Loss': best_val_loss,\n",
    "        'Best Val MAE': best_val_mae,\n",
    "        'Best Val R2': best_val_r2\n",
    "    }, ignore_index=True)\n",
    "    train_records.to_csv(f'train_records_fold_{fold}_epoch_{epoch}.csv', index=False)\n",
    "    val_records.to_csv(f'val_records_fold_{fold}_epoch_{epoch}.csv', index=False)\n",
    "\n",
    "    # print(f\"Completed Fold {fold}\")\n",
    "\n",
    "# writer.close()\n",
    "print(\"Training completed.\")\n",
    "# print(\"Fold Results:\\n\", fold_results)\n",
    "\n",
    "MRI_dir = \"./RawDataset/MRIs/\"\n",
    "# tabular_dir = \"./RawDataset/Clinical_and_Other_Features.xlsx\"\n",
    "tabular_dir = \"./RawDataset/cleaned.csv\"\n",
    "main(MRI_dir=MRI_dir, tabular_dir=tabular_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(test_data_dir, bone_type, model_path):\n",
    "    \"\"\"\n",
    "    Main method to train the ResNet on a training dataset\n",
    "\n",
    "    Parameters:\n",
    "    - test_data_dir (Str): Directory containing the test dataset of HR-pQCT images\n",
    "    - bone_type (char): Which bone is being evaluated (Radius or Tibia)\n",
    "    - model_path: Path to where the previously trained model is saved\n",
    "\n",
    "    Returns:\n",
    "    - Nothing\n",
    "    - Saves the performance metrics to a .csv file\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = load_model(model_path).to(device)\n",
    "    \n",
    "    test_dataset_transforms = Compose([ScaleIntensity(), EnsureChannelFirst(channel_dim=0)])\n",
    "    test_dataset = TensorDataset(test_data_dir, bone_type, transform=test_dataset_transforms)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, num_workers=0, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "    predictions, targets, mae, r2, mse = evaluate_model(model, test_loader, device)\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Predictions': predictions,\n",
    "        'Targets': targets,\n",
    "        'MAE': [mae] * len(predictions),\n",
    "        'R2': [r2] * len(predictions),\n",
    "        'MSE':  [mse] * len(predictions)\n",
    "    })\n",
    "\n",
    "    results_df.to_csv('/home/sergiu.cociuba/BoneLab/DAFT/daft/test_results_daft.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
